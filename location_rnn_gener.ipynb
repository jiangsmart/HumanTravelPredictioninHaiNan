{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 输入训练路径\n",
    "train_path = '/home/jiang/data/sorted10000'\n",
    "# 基站路径\n",
    "station_path = '/home/jiang/data/stationRecord'\n",
    "# 输入长度\n",
    "maxlen = 150\n",
    "# 输入中某地（如海口）大于该值，进入训练集\n",
    "threshold = 120\n",
    "# 滚动步长\n",
    "step = 1\n",
    "# 测试长度\n",
    "testlen = 50\n",
    "batch_size=16\n",
    "num_skips=2\n",
    "skip_window=2\n",
    "data_index1=0\n",
    "data_index2=0\n",
    "station_size=200\n",
    "lr=0.01\n",
    "\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "num_steps = 2000\n",
    "\n",
    "station_size = 10000\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(train_path):\n",
    "    file_object = open(train_path)\n",
    "    train_list = file_object.readlines()\n",
    "    train_set=[]\n",
    "    user_record=[]\n",
    "    station_list=[]\n",
    "    station_set=set()\n",
    "    for i,record in enumerate(train_list):\n",
    "        record=record.strip()\n",
    "        user,station=(record.split(\",\")[j] for j in [0,3])\n",
    "        station_set.add(int(station))\n",
    "        if i == len(train_list)-1:\n",
    "            user_record.append(int(station))\n",
    "            train_set.append(user_record)\n",
    "            station_list=sorted(list(station_set))\n",
    "            return train_set,station_list\n",
    "        elif user != train_list[i+1].split(\",\")[0]:\n",
    "            user_record.append(int(station))\n",
    "            train_set.append(user_record)\n",
    "            user_record=[]\n",
    "        else:\n",
    "            user_record.append(int(station))\n",
    "    #return train_set,station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#注意不要让序列小于3个的序列进入\n",
    "def generate_batch(data, batch_size, num_skips, skip_window):\n",
    "    global data_index1\n",
    "    global data_index2\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    #print len(data[data_index1])\n",
    "    for i in range(batch_size // num_skips):\n",
    "        #第一次进入循环初始化buffer\n",
    "        if i == 0:\n",
    "            while len(data[data_index1])-data_index2 < span:\n",
    "                data_index2 = 0\n",
    "                data_index1 = (data_index1 + 1)%len(data)                \n",
    "            for _ in range(span-1):\n",
    "                buffer.append(data[data_index1][data_index2])\n",
    "                data_index2 += 1\n",
    "        ###############################\n",
    "        #index更新后判断是否越界\n",
    "        if data_index2 == (len(data[data_index1])):\n",
    "            data_index2 = 0\n",
    "            data_index1 = (data_index1 + 1)%len(data)\n",
    "            while len(data[data_index1])-data_index2 < span:\n",
    "                data_index1 = (data_index1 + 1)%len(data)\n",
    "            for _ in range(span-1):\n",
    "                buffer.append(data[data_index1][data_index2])\n",
    "                data_index2 += 1\n",
    "        #################################\n",
    "        #print data_index1,data_index2 \n",
    "        buffer.append(data[data_index1][data_index2])\n",
    "        #print buffer\n",
    "        data_index2 += 1\n",
    "        target = skip_window  # input word at the center of the buffer\n",
    "        targets_to_avoid = [skip_window]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]  # this is the input word\n",
    "            context[i * num_skips + j, 0] = buffer[target]  # these are the context words\n",
    "        \n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    #data_index2 = (data_index2 + len(data) - span) % len(data)\n",
    "    return batch, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recount_data(data,station_indices):\n",
    "    new_data=[]\n",
    "    for record in data:\n",
    "        new_record=[]\n",
    "        for station in record:\n",
    "            new_record.append(station_indices[station])\n",
    "        new_data.append(new_record)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_pre(train_path):\n",
    "    train_data,station_data=read_data(train_path)\n",
    "    sum_station = len(station_data)\n",
    "    station_indices = dict((c, i) for i, c in enumerate(station_data))\n",
    "    indices_station = dict((i, c) for i, c in enumerate(station_data))\n",
    "    train_data = recount_data(train_data,station_indices)\n",
    "    return train_data,sum_station,indices_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n"
     ]
    }
   ],
   "source": [
    "data,station_num,indices_station=data_pre(train_path)\n",
    "print station_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_context = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "  # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "      tf.random_uniform([station_num, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "    \n",
    "    \n",
    "    # Construct the variables for the NCE loss\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([station_num, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([station_num]))\n",
    "\n",
    "    nce_loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(weights=nce_weights,\n",
    "                       biases=nce_biases,\n",
    "                       labels=train_context,\n",
    "                       inputs=embed,\n",
    "                       num_sampled=num_sampled,\n",
    "                       num_classes=station_num))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(nce_loss)\n",
    "    \n",
    "#   # Construct the variables for the softmax\n",
    "#     weights = tf.Variable(tf.truncated_normal([embedding_size, station_num],\n",
    "#                                               stddev=1.0 / math.sqrt(embedding_size)))\n",
    "#     biases = tf.Variable(tf.zeros([station_num]))\n",
    "#     hidden_out = tf.transpose(tf.matmul(tf.transpose(weights), tf.transpose(embed))) + biases\n",
    "\n",
    "#   # convert train_context to a one-hot format\n",
    "#     train_one_hot = tf.one_hot(train_context, station_num)\n",
    "\n",
    "#     cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hidden_out, labels=train_one_hot))\n",
    "\n",
    "#   # Construct the SGD optimizer using a learning rate of lr.\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "  # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    \n",
    "    #只保存embeddings\n",
    "    #saver = tf.train.Saver({\"station_embeddings\": embeddings})\n",
    "    #保存全部变量\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "  # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./data/station_embedding.ckpt\n",
      "Nearest to 10773: 32113, 10331, 10311, 21512, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 15391, 19811, 21953, 47261, 50111, 11081,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 42313, 18101, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 10141,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 11393, 43373,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 42033, 13122, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 30663,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 21953, 13582, 43363, 38129, 43403, 19261,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12182,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 10, ': ', 15.054126191139222)\n",
      "('Average loss at step ', 20, ': ', 15.3642653465271)\n",
      "('Average loss at step ', 30, ': ', 13.908375358581543)\n",
      "('Average loss at step ', 40, ': ', 6.7794025063514711)\n",
      "('Average loss at step ', 50, ': ', 18.404206848144533)\n",
      "('Average loss at step ', 60, ': ', 17.291499710083009)\n",
      "('Average loss at step ', 70, ': ', 16.595525550842286)\n",
      "('Average loss at step ', 80, ': ', 17.61995267868042)\n",
      "('Average loss at step ', 90, ': ', 17.595115947723389)\n",
      "('Average loss at step ', 100, ': ', 10.139416575431824)\n",
      "('Average loss at step ', 110, ': ', 4.4755267381668089)\n",
      "('Average loss at step ', 120, ': ', 10.390071535110474)\n",
      "('Average loss at step ', 130, ': ', 16.381359314918519)\n",
      "('Average loss at step ', 140, ': ', 27.229123926162721)\n",
      "('Average loss at step ', 150, ': ', 11.410096406936646)\n",
      "('Average loss at step ', 160, ': ', 35.227149844169617)\n",
      "('Average loss at step ', 170, ': ', 17.070375919342041)\n",
      "('Average loss at step ', 180, ': ', 19.23376202583313)\n",
      "('Average loss at step ', 190, ': ', 11.340653324127198)\n",
      "('Average loss at step ', 200, ': ', 14.538172721862793)\n",
      "Nearest to 10773: 32113, 10331, 10311, 21512, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 42313, 18101, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 10141,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 11393, 42351,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 42033, 13122, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 30663,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 11813, 49011, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 21953, 13582, 43363, 38129, 43403, 19261,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12182,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 210, ': ', 16.321794509887695)\n",
      "('Average loss at step ', 220, ': ', 20.640215778350829)\n",
      "('Average loss at step ', 230, ': ', 11.200134706497192)\n",
      "('Average loss at step ', 240, ': ', 14.275802230834961)\n",
      "('Average loss at step ', 250, ': ', 17.960076427459718)\n",
      "('Average loss at step ', 260, ': ', 12.901508903503418)\n",
      "('Average loss at step ', 270, ': ', 8.4293156147003181)\n",
      "('Average loss at step ', 280, ': ', 14.173542594909668)\n",
      "('Average loss at step ', 290, ': ', 16.857969713211059)\n",
      "('Average loss at step ', 300, ': ', 11.472259473800658)\n",
      "('Average loss at step ', 310, ': ', 12.975745105743409)\n",
      "('Average loss at step ', 320, ': ', 9.2996797084808343)\n",
      "('Average loss at step ', 330, ': ', 10.289885520935059)\n",
      "('Average loss at step ', 340, ': ', 10.000698041915893)\n",
      "('Average loss at step ', 350, ': ', 19.199584507942198)\n",
      "('Average loss at step ', 360, ': ', 11.366744375228881)\n",
      "('Average loss at step ', 370, ': ', 20.174542045593263)\n",
      "('Average loss at step ', 380, ': ', 17.098408031463624)\n",
      "('Average loss at step ', 390, ': ', 7.8241292417049406)\n",
      "('Average loss at step ', 400, ': ', 6.859254619479179)\n",
      "Nearest to 10773: 32113, 10331, 10311, 21512, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 42313, 18101, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 10141,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 11393, 42351,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 14813, 13021, 38127, 30292, 42033, 13122, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 30663,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 21953, 43403, 38129, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 12602, 13803, 12182,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 410, ': ', 5.4105894863605499)\n",
      "('Average loss at step ', 420, ': ', 9.0539984107017517)\n",
      "('Average loss at step ', 430, ': ', 13.779901450872421)\n",
      "('Average loss at step ', 440, ': ', 27.860781145095824)\n",
      "('Average loss at step ', 450, ': ', 9.7271132230758663)\n",
      "('Average loss at step ', 460, ': ', 10.523018252849578)\n",
      "('Average loss at step ', 470, ': ', 7.3298109769821167)\n",
      "('Average loss at step ', 480, ': ', 6.1949659585952759)\n",
      "('Average loss at step ', 490, ': ', 8.5232261657714847)\n",
      "('Average loss at step ', 500, ': ', 26.426107358932494)\n",
      "('Average loss at step ', 510, ': ', 3.2695925235748291)\n",
      "('Average loss at step ', 520, ': ', 3.5717814624309541)\n",
      "('Average loss at step ', 530, ': ', 7.4249059319496151)\n",
      "('Average loss at step ', 540, ': ', 1.9636068165302276)\n",
      "('Average loss at step ', 550, ': ', 3.3065840184688566)\n",
      "('Average loss at step ', 560, ': ', 6.1727712780237196)\n",
      "('Average loss at step ', 570, ': ', 4.0137270554900173)\n",
      "('Average loss at step ', 580, ': ', 1.0038524940609932)\n",
      "('Average loss at step ', 590, ': ', 1.1668875768780709)\n",
      "('Average loss at step ', 600, ': ', 5.7369987666606903)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 42313, 18101, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 10141,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 11393, 42351,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 14813, 13021, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 30663,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 21953, 38129, 43403, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12182,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 610, ': ', 16.764983296394348)\n",
      "('Average loss at step ', 620, ': ', 0.66302117258310322)\n",
      "('Average loss at step ', 630, ': ', 0.85811880528926854)\n",
      "('Average loss at step ', 640, ': ', 3.7321256890892984)\n",
      "('Average loss at step ', 650, ': ', 15.373434662818909)\n",
      "('Average loss at step ', 660, ': ', 5.6615754842758177)\n",
      "('Average loss at step ', 670, ': ', 12.324473595619201)\n",
      "('Average loss at step ', 680, ': ', 12.496014344692231)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step ', 690, ': ', 13.646129512786866)\n",
      "('Average loss at step ', 700, ': ', 8.2581789493560791)\n",
      "('Average loss at step ', 710, ': ', 15.784983491897583)\n",
      "('Average loss at step ', 720, ': ', 23.372243976593019)\n",
      "('Average loss at step ', 730, ': ', 25.353354358673094)\n",
      "('Average loss at step ', 740, ': ', 20.283594322204589)\n",
      "('Average loss at step ', 750, ': ', 15.153756856918335)\n",
      "('Average loss at step ', 760, ': ', 21.870773124694825)\n",
      "('Average loss at step ', 770, ': ', 23.121040630340577)\n",
      "('Average loss at step ', 780, ': ', 21.684462070465088)\n",
      "('Average loss at step ', 790, ': ', 18.823307895660399)\n",
      "('Average loss at step ', 800, ': ', 25.750524139404298)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 42313, 18101, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 11393, 42351,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 18566, 12061, 50243, 15392, 20323, 30663,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 21953, 38129, 43403, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12182,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 810, ': ', 18.433087491989134)\n",
      "('Average loss at step ', 820, ': ', 19.420642375946045)\n",
      "('Average loss at step ', 830, ': ', 19.436122941970826)\n",
      "('Average loss at step ', 840, ': ', 10.933294022083283)\n",
      "('Average loss at step ', 850, ': ', 12.815066432952881)\n",
      "('Average loss at step ', 860, ': ', 12.485255789756774)\n",
      "('Average loss at step ', 870, ': ', 6.6068618416786196)\n",
      "('Average loss at step ', 880, ': ', 15.872718071937561)\n",
      "('Average loss at step ', 890, ': ', 15.545736837387086)\n",
      "('Average loss at step ', 900, ': ', 20.146756362915038)\n",
      "('Average loss at step ', 910, ': ', 12.382879400253296)\n",
      "('Average loss at step ', 920, ': ', 11.294159269332885)\n",
      "('Average loss at step ', 930, ': ', 8.002043437957763)\n",
      "('Average loss at step ', 940, ': ', 5.0162041068077086)\n",
      "('Average loss at step ', 950, ': ', 8.6880359172821038)\n",
      "('Average loss at step ', 960, ': ', 18.404305386543275)\n",
      "('Average loss at step ', 970, ': ', 22.444544744491576)\n",
      "('Average loss at step ', 980, ': ', 16.836453485488892)\n",
      "('Average loss at step ', 990, ': ', 33.004070186614989)\n",
      "('Average loss at step ', 1000, ': ', 12.665164279937745)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 23263,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 18101, 42313, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 42351, 11393,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 11872,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 21953, 38129, 43403, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12002,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 1010, ': ', 13.662692832946778)\n",
      "('Average loss at step ', 1020, ': ', 13.162248039245606)\n",
      "('Average loss at step ', 1030, ': ', 13.525354862213135)\n",
      "('Average loss at step ', 1040, ': ', 12.541536331176758)\n",
      "('Average loss at step ', 1050, ': ', 17.883361053466796)\n",
      "('Average loss at step ', 1060, ': ', 10.065586423873901)\n",
      "('Average loss at step ', 1070, ': ', 14.895933866500854)\n",
      "('Average loss at step ', 1080, ': ', 16.320328807830812)\n",
      "('Average loss at step ', 1090, ': ', 10.266789340972901)\n",
      "('Average loss at step ', 1100, ': ', 7.7061363697052006)\n",
      "('Average loss at step ', 1110, ': ', 13.162995052337646)\n",
      "('Average loss at step ', 1120, ': ', 14.880218839645385)\n",
      "('Average loss at step ', 1130, ': ', 11.592037010192872)\n",
      "('Average loss at step ', 1140, ': ', 9.5835792064666752)\n",
      "('Average loss at step ', 1150, ': ', 10.124367380142212)\n",
      "('Average loss at step ', 1160, ': ', 7.9994460940361023)\n",
      "('Average loss at step ', 1170, ': ', 10.004198575019837)\n",
      "('Average loss at step ', 1180, ': ', 15.889837002754211)\n",
      "('Average loss at step ', 1190, ': ', 12.750058460235596)\n",
      "('Average loss at step ', 1200, ': ', 17.145960199832917)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 23263,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 18101, 42313, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 42351, 11393,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 14813, 13021, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 11872,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 43403, 21953, 38129, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12002,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 1210, ': ', 13.691772949695586)\n",
      "('Average loss at step ', 1220, ': ', 4.4023033499717714)\n",
      "('Average loss at step ', 1230, ': ', 5.7350449919700619)\n",
      "('Average loss at step ', 1240, ': ', 8.8981918573379524)\n",
      "('Average loss at step ', 1250, ': ', 4.8486215651035307)\n",
      "('Average loss at step ', 1260, ': ', 15.324183464050293)\n",
      "('Average loss at step ', 1270, ': ', 19.650958704948426)\n",
      "('Average loss at step ', 1280, ': ', 9.3563553810119622)\n",
      "('Average loss at step ', 1290, ': ', 9.3379614591598514)\n",
      "('Average loss at step ', 1300, ': ', 6.5552536010742184)\n",
      "('Average loss at step ', 1310, ': ', 5.5941920757293699)\n",
      "('Average loss at step ', 1320, ': ', 9.3917491912841804)\n",
      "('Average loss at step ', 1330, ': ', 21.423932337760924)\n",
      "('Average loss at step ', 1340, ': ', 1.6672146797180176)\n",
      "('Average loss at step ', 1350, ': ', 2.9417701303958892)\n",
      "('Average loss at step ', 1360, ': ', 5.8077615946531296)\n",
      "('Average loss at step ', 1370, ': ', 3.207333391904831)\n",
      "('Average loss at step ', 1380, ': ', 1.8718620985746384)\n",
      "('Average loss at step ', 1390, ': ', 7.3052019208669661)\n",
      "('Average loss at step ', 1400, ': ', 1.5860574007034303)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 47312, 19811, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 42152,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 18101, 42313, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42292, 42501, 43741, 42351, 11393,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 14813, 13021, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 11872,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 43403, 38129, 21953, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12002,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 1410, ': ', 1.3091301202774048)\n",
      "('Average loss at step ', 1420, ': ', 0.69808717966079714)\n",
      "('Average loss at step ', 1430, ': ', 4.9780175030231479)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step ', 1440, ': ', 13.790077114105225)\n",
      "('Average loss at step ', 1450, ': ', 0.74666515290737157)\n",
      "('Average loss at step ', 1460, ': ', 1.1297217816114427)\n",
      "('Average loss at step ', 1470, ': ', 5.8842518404126167)\n",
      "('Average loss at step ', 1480, ': ', 13.306545245647431)\n",
      "('Average loss at step ', 1490, ': ', 5.8775837957859043)\n",
      "('Average loss at step ', 1500, ': ', 15.027419805526733)\n",
      "('Average loss at step ', 1510, ': ', 7.5532803058624269)\n",
      "('Average loss at step ', 1520, ': ', 11.808721613883971)\n",
      "('Average loss at step ', 1530, ': ', 6.6241594791412357)\n",
      "('Average loss at step ', 1540, ': ', 15.436310768127441)\n",
      "('Average loss at step ', 1550, ': ', 22.326939392089844)\n",
      "('Average loss at step ', 1560, ': ', 24.768576145172119)\n",
      "('Average loss at step ', 1570, ': ', 14.073309183120728)\n",
      "('Average loss at step ', 1580, ': ', 16.263311862945557)\n",
      "('Average loss at step ', 1590, ': ', 20.292783641815184)\n",
      "('Average loss at step ', 1600, ': ', 20.485971641540527)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 19811, 47312, 15391, 21953, 47261, 11081, 50111,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 23263,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 19071, 49222, 20062, 18101, 42313, 39111,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42501, 42292, 43741, 42351, 11393,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 11872,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 11813, 30901, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 43403, 38129, 21953, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12002,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 1610, ': ', 22.170984935760497)\n",
      "('Average loss at step ', 1620, ': ', 18.673531675338744)\n",
      "('Average loss at step ', 1630, ': ', 19.812127780914306)\n",
      "('Average loss at step ', 1640, ': ', 20.72629632949829)\n",
      "('Average loss at step ', 1650, ': ', 21.280195569992067)\n",
      "('Average loss at step ', 1660, ': ', 13.070642447471618)\n",
      "('Average loss at step ', 1670, ': ', 10.804889607429505)\n",
      "('Average loss at step ', 1680, ': ', 9.3748862743377686)\n",
      "('Average loss at step ', 1690, ': ', 9.8494044065475457)\n",
      "('Average loss at step ', 1700, ': ', 7.7144688487052919)\n",
      "('Average loss at step ', 1710, ': ', 12.911146986484528)\n",
      "('Average loss at step ', 1720, ': ', 17.010557889938354)\n",
      "('Average loss at step ', 1730, ': ', 18.029150629043578)\n",
      "('Average loss at step ', 1740, ': ', 10.006546413898468)\n",
      "('Average loss at step ', 1750, ': ', 12.208229494094848)\n",
      "('Average loss at step ', 1760, ': ', 3.9469884753227236)\n",
      "('Average loss at step ', 1770, ': ', 7.04079692363739)\n",
      "('Average loss at step ', 1780, ': ', 4.4881597280502321)\n",
      "('Average loss at step ', 1790, ': ', 24.315007424354555)\n",
      "('Average loss at step ', 1800, ': ', 12.529012417793274)\n",
      "Nearest to 10773: 32113, 10331, 21512, 10311, 15681, 42933, 43252, 44041,\n",
      "Nearest to 10603: 43362, 19811, 15391, 47312, 21953, 47261, 11081, 44203,\n",
      "Nearest to 10782: 30854, 43831, 43431, 12903, 12113, 11962, 11342, 23263,\n",
      "Nearest to 10701: 15192, 43732, 13881, 50561, 24333, 44501, 44011, 10747,\n",
      "Nearest to 10472: 19943, 43512, 49222, 19071, 18101, 20062, 39111, 13541,\n",
      "Nearest to 10802: 10271, 43482, 10811, 13231, 31181, 13713, 14813, 42311,\n",
      "Nearest to 10383: 43861, 19114, 13713, 50021, 31262, 12793, 30292, 13233,\n",
      "Nearest to 10532: 13133, 42201, 17012, 42501, 42292, 43741, 42351, 11393,\n",
      "Nearest to 10671: 13273, 42493, 47201, 50243, 42202, 44091, 13353, 42321,\n",
      "Nearest to 10271: 13713, 13021, 14813, 38127, 30292, 13122, 42033, 50021,\n",
      "Nearest to 10351: 22106, 43953, 14011, 13571, 10641, 30901, 11262, 42561,\n",
      "Nearest to 10401: 14122, 43253, 12061, 18566, 50243, 15392, 20323, 11872,\n",
      "Nearest to 10181: 11762, 42521, 43483, 19071, 49011, 30901, 11813, 13133,\n",
      "Nearest to 10071: 42801, 47051, 13582, 43403, 38129, 21953, 43363, 14273,\n",
      "Nearest to 10883: 44451, 41233, 15631, 13821, 14741, 13803, 12602, 12002,\n",
      "Nearest to 10295: 50061, 25793, 12892, 13362, 43865, 30513, 44102, 48153,\n",
      "('Average loss at step ', 1810, ': ', 23.927140712738037)\n",
      "('Average loss at step ', 1820, ': ', 22.231446552276612)\n",
      "('Average loss at step ', 1830, ': ', 10.901867771148682)\n",
      "('Average loss at step ', 1840, ': ', 11.170304489135741)\n",
      "('Average loss at step ', 1850, ': ', 12.903476428985595)\n",
      "('Average loss at step ', 1860, ': ', 13.416681528091431)\n",
      "('Average loss at step ', 1870, ': ', 10.831952333450317)\n",
      "('Average loss at step ', 1880, ': ', 13.356861782073974)\n",
      "('Average loss at step ', 1890, ': ', 12.505438184738159)\n",
      "('Average loss at step ', 1900, ': ', 9.2509811162948612)\n",
      "('Average loss at step ', 1910, ': ', 14.18044376373291)\n",
      "('Average loss at step ', 1920, ': ', 8.5131614446640018)\n",
      "('Average loss at step ', 1930, ': ', 8.8370200157165524)\n",
      "('Average loss at step ', 1940, ': ', 11.684507083892822)\n",
      "('Average loss at step ', 1950, ': ', 11.807681179046631)\n",
      "('Average loss at step ', 1960, ': ', 9.2171581745147702)\n",
      "('Average loss at step ', 1970, ': ', 9.4463960647583001)\n",
      "('Average loss at step ', 1980, ': ', 10.251167178153992)\n",
      "('Average loss at step ', 1990, ': ', 6.4269797801971436)\n",
      "Softmax method took 3.738038 secs to run\n"
     ]
    }
   ],
   "source": [
    "session=tf.Session(graph=graph)\n",
    "average_loss = 0\n",
    "softmax_start_time = dt.datetime.now()\n",
    "#重新训练使用session.run(init)\n",
    "#session.run(init)\n",
    "#载入之前的训练结果用saver\n",
    "saver.restore(session, \"./data/station_embedding.ckpt\")\n",
    "for step in range(num_steps):\n",
    "    batch_inputs, batch_context = generate_batch(data,batch_size, num_skips, skip_window)\n",
    "    #print batch_inputs,batch_context\n",
    "    feed_dict = {train_inputs: batch_inputs, train_context: batch_context}\n",
    "    #print feed_dict\n",
    "    _, loss_val = session.run([optimizer, nce_loss], feed_dict=feed_dict)\n",
    "    #_, loss_val = session.run([optimizer, cross_entropy], feed_dict=feed_dict)\n",
    "    average_loss += loss_val\n",
    "    #print step\n",
    "    if step % 10 == 0:\n",
    "        if step > 0:\n",
    "            average_loss /= 10\n",
    "    # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss)\n",
    "            average_loss = 0\n",
    "\n",
    "    # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "    if step % 200 == 0:\n",
    "        sim = similarity.eval(session=session)\n",
    "        for i in range(valid_size):\n",
    "            valid_station = indices_station[valid_examples[i]]\n",
    "            top_k = 8  # number of nearest neighbors\n",
    "            nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "            log_str = 'Nearest to %s:' % valid_station\n",
    "            for k in range(top_k):\n",
    "                close_station = indices_station[nearest[k]]\n",
    "                log_str = '%s %s,' % (log_str, close_station)\n",
    "            print(log_str)\n",
    "            \n",
    "save_path = saver.save(session, \"./data/station_embedding.ckpt\")\n",
    "    \n",
    "#final_embeddings = normalized_embeddings.eval(session=session)\n",
    "softmax_end_time = dt.datetime.now()\n",
    "print(\"Softmax method took {} secs to run\".format((softmax_end_time-softmax_start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
